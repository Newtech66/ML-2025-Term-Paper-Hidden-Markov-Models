{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2414fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, output_states, hidden_states, i_vector=None, t_matrix=None, e_matrix=None):\n",
    "        # The set of possible emissions\n",
    "        self.output_set = output_states\n",
    "        # The number of possible emissions\n",
    "        self.n_emissions = len(output_states)\n",
    "        # Observable-to-index map\n",
    "        self.observable_to_index_map = {o: i for i, o in enumerate(self.output_set)}\n",
    "        # Index-to-observable map\n",
    "        self.index_to_observable_map = {i: o for o, i in self.observable_to_index_map.items()}\n",
    "        # The set of hidden states\n",
    "        self.hidden_set = hidden_states\n",
    "        # The number of hidden states\n",
    "        self.n_states = len(hidden_states)\n",
    "        # Observable-to-index map\n",
    "        self.hidden_to_index_map = {o: i for i, o in enumerate(self.hidden_set)}\n",
    "        # Index-to-observable map\n",
    "        self.index_to_hidden_map = {i: o for o, i in self.hidden_to_index_map.items()}\n",
    "        # The probability of starting in a particular state\n",
    "        if i_vector is None:\n",
    "            self.i_vector = np.ones(self.n_states, 1) / self.n_states\n",
    "        else:\n",
    "            assert i_vector.shape == (self.n_states,)\n",
    "            self.i_vector = i_vector\n",
    "        self.i_vector = self.i_vector\n",
    "        # The transition probabilities\n",
    "        # T[i, j] = probability of going from i to j\n",
    "        if t_matrix is None:\n",
    "            self.t_matrix = self.ones((self.n_states, self.n_states)) / self.n_states ** 2\n",
    "        else:\n",
    "            assert t_matrix.shape == (self.n_states, self.n_states)\n",
    "            self.t_matrix = t_matrix\n",
    "        # The emission probabilities\n",
    "        # E[i, o] = probability of emitting o from i\n",
    "        if e_matrix is None:\n",
    "            self.e_matrix = self.ones((self.n_states, self.n_emissions)) / (self.n_states * self.n_emissions)\n",
    "        else:\n",
    "            assert e_matrix.shape == (self.n_states, self.n_emissions)\n",
    "            self.e_matrix = e_matrix\n",
    "    \n",
    "    def observable_to_index(self, X):\n",
    "        # Convert observables to indices\n",
    "        return [self.observable_to_index_map[x] for x in X]\n",
    "\n",
    "    def index_to_observable(self, X):\n",
    "        # Convert indices to observables\n",
    "        return [self.index_to_observable_map[x] for x in X]\n",
    "\n",
    "    def hidden_to_index(self, X):\n",
    "        # Convert hiddens to indices\n",
    "        return [self.hidden_to_index_map[x] for x in X]\n",
    "\n",
    "    def index_to_hidden(self, X):\n",
    "        # Convert indices to hiddens\n",
    "        return [self.index_to_hidden_map[x] for x in X]\n",
    "\n",
    "    def observable_sequence_emission_probability(self, O):\n",
    "        # Find the probability of generating the observable sequence O given the model\n",
    "        # parameters. We will use the Forward algorithm for this.\n",
    "\n",
    "        # Convert to indices\n",
    "        X = self.observable_to_index(O)\n",
    "\n",
    "        # Probabilities at first timestep\n",
    "        alpha = self.i_vector * self.e_matrix[:, X[0]]\n",
    "        # Iteration\n",
    "        for i in range(1, len(X)):\n",
    "            alpha = (alpha @ self.t_matrix) * self.e_matrix[:, X[i]]\n",
    "        return np.sum(alpha)\n",
    "    \n",
    "    def most_likely_hidden_sequence(self, O):\n",
    "        # Find the most likely hidden sequence H that generated the observable sequence O.\n",
    "        # We will use the Viterbi algorithm for this.\n",
    "\n",
    "        # Convert to indices\n",
    "        X = self.observable_to_index(O)\n",
    "\n",
    "        # Probabilities at first timestep\n",
    "        alpha = self.i_vector * self.e_matrix[:, X[0]].T\n",
    "        # Backtrace\n",
    "        beta = -np.ones((len(X), self.n_states), dtype=np.int32)\n",
    "        # Iteration\n",
    "        for i in range(1, len(X)):\n",
    "            nxt = alpha * self.t_matrix.T\n",
    "            alpha = nxt.max(axis=1) * self.e_matrix[:, X[i]]\n",
    "            beta[i, :] = nxt.argmax(axis=1)\n",
    "        \n",
    "        # Termination\n",
    "        i, j = alpha.argmax(), -1\n",
    "        H = []\n",
    "        while i >= 0:\n",
    "            H.append(i)\n",
    "            i = beta[j, i]\n",
    "            j -= 1\n",
    "        H.reverse()\n",
    "\n",
    "        return self.index_to_hidden(H)\n",
    "\n",
    "    def single_sample_train(self, O):\n",
    "        # Find the maximum likelihood estimate for the model parameters that could generate\n",
    "        # the observable sequence O. We will use the Baum-Welch algorithm for this.\n",
    "        # The Baum-Welch algorithm does not guarantee a global maximum will be found.\n",
    "        alpha = np.zeros((self.n_states, self.n_emissions))\n",
    "        beta = np.zeros((self.n_states, self.n_emissions))\n",
    "        gamma = np.zeros((self.n_states, self.n_emissions))\n",
    "        xi = np.zeros((self.n_states, self.n_states, self.n_emissions))\n",
    "\n",
    "        # Convert to indices\n",
    "        X = self.observable_to_index(O)\n",
    "        # Calculate the forward probabilities\n",
    "        alpha[:, 0] = self.i_vector * self.e_matrix[:, X[0]]\n",
    "        for i in range(1, len(X)):\n",
    "            alpha[:, i] = (alpha[:, i - 1] @ self.t_matrix) * self.e_matrix[:, X[i]]\n",
    "        # Calculate the backward probabilities\n",
    "        beta[:, -1] = np.ones(self.n_states)\n",
    "        for i in range(-2, -len(X)-1, -1):\n",
    "            beta[:, i] = self.t_matrix @ (self.e_matrix[:, X[i + 1]] * beta[:, i + 1])\n",
    "        # Calculate gamma and xi\n",
    "        gamma = alpha * beta / np.sum(alpha * beta)\n",
    "        for i in range(len(X) - 1):\n",
    "            xi[:, :, i] = ((alpha[:, i] * self.t_matrix).T * (self.e_matrix[:, X[i + 1]] * beta[:, i + 1])).T\n",
    "        xi /= np.sum(alpha * beta)\n",
    "        # Calculate the updated values\n",
    "        self.i_vector = gamma[:, 0]\n",
    "        self.t_matrix = np.sum(xi[:, :, :len(X) - 1], axis=2) / np.sum(gamma[:, :len(X) - 1], axis=1)\n",
    "        for k in range(self.n_emissions):\n",
    "            for j in range(self.n_states):\n",
    "                self.e_matrix[j, k] = np.sum(np.where(np.array(X) == k, gamma[j, :], 0.0)) / np.sum(gamma[j, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c75a2080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Healthy', 'Healthy', 'Fever']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = ['Healthy', 'Fever']\n",
    "output = ['Normal', 'Cold', 'Dizzy']\n",
    "init = np.array([0.6, 0.4])\n",
    "transition = np.array([\n",
    "    [0.7, 0.3],\n",
    "    [0.4, 0.6],\n",
    "])\n",
    "emission = np.array([\n",
    "    [0.5, 0.4, 0.1],\n",
    "    [0.1, 0.3, 0.6],\n",
    "])\n",
    "hmm = HMM(output, hidden, init, transition, emission)\n",
    "hmm.most_likely_hidden_sequence(['Normal', 'Cold', 'Dizzy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "80bc66b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.37840370e-163, 1.00000000e+000, 6.25599121e-165],\n",
       "       [3.33333333e-001, 3.33333333e-001, 3.33333333e-001]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.single_sample_train(['Normal', 'Cold', 'Dizzy'])\n",
    "hmm.e_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat-ml-hep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
